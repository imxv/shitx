import { NextResponse } from 'next/server';
import { generateText } from 'ai';
import { createKimiProvider, getKimiModel } from '@/lib/ai-providers/kimi-provider';
import { redis, nftRedis } from '@/lib/redis';
import * as mock from '@/lib/mockImplementation';

const ANALYSIS_COST = 100; // 100 SHIT per analysis
const CACHE_DURATION = 24 * 60 * 60; // 24 hours in seconds

export async function POST(request: Request) {
  try {
    const { type, forceRefresh = false, userAddress } = await request.json();
    
    if (!userAddress) {
      return NextResponse.json({ error: 'User address is required' }, { status: 400 });
    }
    
    if (!type || !['grant', 'nft'].includes(type)) {
      return NextResponse.json({ error: 'Invalid analysis type' }, { status: 400 });
    }

    // Normalize address to lowercase
    const normalizedAddress = userAddress.toLowerCase();
    
    // Check if user has enough SHIT (use mock implementation)
    const userBalance = await mock.getBalance(normalizedAddress);
    const balance = parseInt(userBalance) || 0;
    
    console.log('[AI Analysis] Balance check:', {
      originalAddress: userAddress,
      normalizedAddress,
      balance: userBalance,
      parsedBalance: balance
    });
    
    if (balance < ANALYSIS_COST) {
      return NextResponse.json({ 
        error: 'Insufficient SHIT balance', 
        required: ANALYSIS_COST,
        current: balance,
        debug: {
          address: normalizedAddress,
          rawBalance: userBalance
        }
      }, { status: 403 });
    }

    // Check for cached analysis
    const cacheKey = `ai-analysis:${type}:${normalizedAddress}`;
    const cachedAnalysis = redis ? await redis.get(cacheKey) : null;
    
    if (cachedAnalysis && !forceRefresh) {
      const analysis = JSON.parse(cachedAnalysis);
      const now = Date.now();
      const updateTime = new Date(analysis.updateTime).getTime();
      const ageInHours = (now - updateTime) / (1000 * 60 * 60);
      
      return NextResponse.json({
        ...analysis,
        cached: true,
        ageInHours: Math.round(ageInHours * 10) / 10,
        nextUpdateCost: ANALYSIS_COST
      });
    }

    // Deduct SHIT cost (use mock implementation)
    const newBalance = balance - ANALYSIS_COST;
    await mock.setBalance(normalizedAddress, newBalance.toString());
    
    // Record the expense
    await nftRedis.recordExpense(
      normalizedAddress,
      ANALYSIS_COST,
      'ai_analysis',
      `AI ${type === 'grant' ? 'Grant' : 'NFT'} Analysis`,
      { type, forceRefresh }
    );

    // Fetch data for analysis
    let analysisData;
    let prompt;
    
    if (type === 'grant') {
      // Get grant distribution data
      const grantData = await getGrantAnalysisData(normalizedAddress);
      analysisData = grantData;
      prompt = generateGrantAnalysisPrompt(grantData);
    } else {
      // Get NFT distribution data
      const nftData = await getNFTAnalysisData(normalizedAddress);
      analysisData = nftData;
      prompt = generateNFTAnalysisPrompt(nftData);
    }

    // Generate AI analysis
    const apiKey = process.env.KIMI_API_KEY || process.env.MOONSHOT_API_KEY;
    if (!apiKey) {
      return NextResponse.json({ error: 'AI service not configured' }, { status: 500 });
    }

    const kimi = createKimiProvider(apiKey);
    const { text } = await generateText({
      model: getKimiModel(kimi, 'kimi-k2'),
      system: 'ä½ æ˜¯ShitXå¹³å°çš„æ•°æ®åˆ†æä¸“å®¶ã€‚ä½ çš„åˆ†æé£æ ¼å¹½é»˜é£è¶£ï¼Œå……æ»¡é»‘è‰²å¹½é»˜ï¼ŒåŒæ—¶ä¿æŒä¸“ä¸šå’Œæ´å¯ŸåŠ›ã€‚ä½ ä¼šç”¨è½»æ¾çš„è¯­æ°”è§£é‡Šå¤æ‚çš„æ•°æ®å…³ç³»ï¼Œè®©ç”¨æˆ·åœ¨å¨±ä¹ä¸­è·å¾—æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚',
      prompt,
      maxTokens: 1500,
    });

    // Store analysis result
    const analysisResult = {
      type,
      analysis: text,
      rawData: analysisData,
      updateTime: new Date().toISOString(),
      cost: ANALYSIS_COST,
      userAddress: normalizedAddress
    };

    if (redis) {
      await redis.setex(cacheKey, CACHE_DURATION, JSON.stringify(analysisResult));
    }

    // Record analysis transaction
    if (redis) {
      await redis.zadd(
        `analysis-history:${normalizedAddress}`,
        Date.now(),
        JSON.stringify({
          type,
          cost: ANALYSIS_COST,
          timestamp: new Date().toISOString()
        })
      );
    }

    return NextResponse.json({
      ...analysisResult,
      cached: false,
      newBalance,
      nextUpdateCost: ANALYSIS_COST
    });

  } catch (error) {
    console.error('AI analysis error:', error);
    return NextResponse.json({ 
      error: 'Analysis failed', 
      details: error instanceof Error ? error.message : 'Unknown error' 
    }, { status: 500 });
  }
}

async function getGrantAnalysisData(userAddress: string) {
  // Get user's grant data (use mock implementation)
  const userGrant = await mock.getBalance(userAddress);
  
  // Get referral tree data
  const referrals = redis ? await redis.smembers(`referrals:${userAddress}`) : [];
  const referredBy = redis ? await redis.get(`referred-by:${userAddress}`) : null;
  
  // Get top grant holders
  const topHolders = redis ? await redis.zrevrange('grant-leaderboard', 0, 9, 'WITHSCORES') : [];
  
  // Calculate network effects
  let totalNetworkGrant = 0;
  let networkDepth = 0;
  
  // First level referrals
  for (const ref of referrals) {
    const refGrant = redis ? await redis.get(`grant:${ref}`) || '0' : '0';
    totalNetworkGrant += parseInt(refGrant) * 0.5; // 50% bonus
    
    // Second level referrals
    const secondLevel = redis ? await redis.smembers(`referrals:${ref}`) : [];
    for (const ref2 of secondLevel) {
      const ref2Grant = redis ? await redis.get(`grant:${ref2}`) || '0' : '0';
      totalNetworkGrant += parseInt(ref2Grant) * 0.1; // 10% bonus
    }
    
    if (secondLevel.length > 0) networkDepth = Math.max(networkDepth, 2);
    else if (referrals.length > 0) networkDepth = Math.max(networkDepth, 1);
  }

  // Get user's rank
  const userRank = redis ? await redis.zrevrank('grant-leaderboard', userAddress) : null;

  return {
    userAddress,
    userGrant: parseInt(userGrant),
    referralCount: referrals.length,
    referredBy,
    totalNetworkGrant,
    networkDepth,
    userRank: userRank !== null ? userRank + 1 : null,
    topHolders: topHolders.reduce((acc, item, index) => {
      if (index % 2 === 0) {
        acc.push({ address: item, grant: parseInt(topHolders[index + 1]) });
      }
      return acc;
    }, [] as { address: string; grant: number }[])
  };
}

async function getNFTAnalysisData(userAddress: string) {
  // Get user's NFT collection
  const nftTypes = ['base', 'dj-teddy', 'wanderpaw', 'snakemaster', 'fomobull', 'pumpfunrugs'];
  const userNFTs: Record<string, any> = {};
  
  for (const nftType of nftTypes) {
    const hasNFT = redis ? await redis.sismember(`nft-holders:${nftType}`, userAddress) : false;
    if (hasNFT) {
      const claimedAt = redis ? await redis.hget(`nft-claims:${nftType}`, userAddress) : null;
      const totalHolders = redis ? await redis.scard(`nft-holders:${nftType}`) : 0;
      const distributionTree = redis ? await redis.smembers(`nft-distributed:${nftType}:${userAddress}`) : [];
      
      userNFTs[nftType] = {
        owned: true,
        claimedAt,
        totalHolders,
        distributedTo: distributionTree.length,
        isAncestor: redis ? await redis.sismember(`ancestors:${nftType}`, userAddress) : false
      };
    }
  }

  // Get NFT rarity stats
  const nftStats = [];
  for (const nftType of nftTypes) {
    const holders = redis ? await redis.scard(`nft-holders:${nftType}`) : 0;
    nftStats.push({ type: nftType, holders });
  }
  nftStats.sort((a, b) => a.holders - b.holders);

  // Calculate collection score
  const ownedCount = Object.keys(userNFTs).length;
  const collectionScore = (ownedCount / nftTypes.length) * 100;

  return {
    userAddress,
    userNFTs,
    ownedCount,
    totalTypes: nftTypes.length,
    collectionScore,
    nftRarityRanking: nftStats,
    isCompleteCollector: ownedCount === nftTypes.length
  };
}

function generateGrantAnalysisPrompt(data: any): string {
  return `åˆ†æä»¥ä¸‹ShitXå¹³å°çš„SHITä»£å¸åˆ†å‘æ•°æ®ï¼š

ç”¨æˆ·åœ°å€ï¼š${data.userAddress}
å½“å‰SHITä½™é¢ï¼š${data.userGrant}
ç›´æ¥æ¨èäººæ•°ï¼š${data.referralCount}
æ¨èç½‘ç»œæ€»æ”¶ç›Šï¼š${data.totalNetworkGrant} SHIT
ç½‘ç»œæ·±åº¦ï¼š${data.networkDepth}å±‚
æ’è¡Œæ¦œæ’åï¼š${data.userRank || 'æœªä¸Šæ¦œ'}

å‰10åæŒæœ‰è€…ï¼š
${data.topHolders.map((h: any, i: number) => `${i + 1}. ${h.address.slice(0, 8)}... - ${h.grant} SHIT`).join('\n')}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. ç”¨æˆ·åœ¨ç”Ÿæ€ä¸­çš„åœ°ä½å’Œå½±å“åŠ›è¯„ä¼°
2. æ¨èç½‘ç»œçš„å¥åº·åº¦å’Œå¢é•¿æ½œåŠ›
3. ä¸é¡¶çº§ç©å®¶çš„å·®è·åˆ†æ
4. 3ä¸ªå…·ä½“çš„å¢é•¿ç­–ç•¥å»ºè®®
5. ä¸€ä¸ªæœ‰è¶£çš„æ•°æ®æ´å¯Ÿ

è®°ä½ç”¨å¹½é»˜çš„æ–¹å¼è¡¨è¾¾ï¼Œè®©æ•°æ®åˆ†æå˜å¾—æœ‰è¶£ï¼`;
}

function generateNFTAnalysisPrompt(data: any): string {
  const ownedNFTs = Object.entries(data.userNFTs)
    .map(([type, info]: [string, any]) => `${type}: ${info.isAncestor ? 'å§‹ç¥–' : 'æŒæœ‰'}, åˆ†å‘ç»™${info.distributedTo}äºº`)
    .join('\n');

  return `åˆ†æä»¥ä¸‹ShitXå¹³å°çš„æé€Ÿå¡ç‰‡(NFT)æ”¶é›†æ•°æ®ï¼š

ç”¨æˆ·åœ°å€ï¼š${data.userAddress}
æ”¶é›†è¿›åº¦ï¼š${data.ownedCount}/${data.totalTypes} (${data.collectionScore.toFixed(1)}%)
${data.isCompleteCollector ? 'ğŸ† å®Œç¾æ”¶è—å®¶ï¼' : ''}

æŒæœ‰çš„æé€Ÿå¡ç‰‡ï¼š
${ownedNFTs || 'æš‚æ— '}

ç¨€æœ‰åº¦æ’åï¼ˆæŒæœ‰äººæ•°ä»å°‘åˆ°å¤šï¼‰ï¼š
${data.nftRarityRanking.map((nft: any, i: number) => `${i + 1}. ${nft.type}: ${nft.holders}äººæŒæœ‰`).join('\n')}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. æ”¶è—å“å‘³è¯„ä»·å’Œç¨€æœ‰åº¦åˆ†æ
2. åœ¨NFTåˆ†å‘ç½‘ç»œä¸­çš„å½±å“åŠ›
3. æœ€æœ‰ä»·å€¼çš„æŒæœ‰å’Œç¼ºå¤±åˆ†æ
4. æ”¶è—ç­–ç•¥å»ºè®®
5. ä¸€ä¸ªå…³äºç”¨æˆ·æ”¶è—é£æ ¼çš„æœ‰è¶£è§‚å¯Ÿ

ç”¨è¯™è°å¹½é»˜çš„æ–¹å¼ï¼Œè®©ç”¨æˆ·æ„Ÿå—åˆ°æ”¶é›†æé€Ÿå¡ç‰‡çš„ä¹è¶£ï¼`;
}